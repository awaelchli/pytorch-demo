{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Best Practices\n",
    "\n",
    "### Practical Advice for Training NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Source Code Organization\n",
    "\n",
    "Make your own skeleton! Keep it lightweight.\n",
    "\n",
    "Recommended folder structure\n",
    "\n",
    "- data\n",
    "- runs\n",
    "- skeleton\n",
    "- models\n",
    "- experiments\n",
    "    - experiment1\n",
    "        - settings.json\n",
    "        - main.py\n",
    "        - train.py\n",
    "        - test.py\n",
    "    - ...\n",
    "- utils\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ArgumentParser vs. Settings File\n",
    "\n",
    "- ArgumentParser defaults are often misused as inputs\n",
    "- W&B can track hyperparameters, but what if we want to share the source code?\n",
    "- Often many hyperparameters (fills your terminal)\n",
    "- Same source code, multiple experiments\n",
    "\n",
    "``` bash\n",
    "\n",
    "python train.py \\ \n",
    "    --log_dir \"../runs/project/experiment\" \n",
    "    --batch_size 10 \\ \n",
    "    --model \"LSTM\" --lr 0.001 --epochs 10 \\\n",
    "    --num_layers 3 --hidden_size 512 \\\n",
    "    --pretrained --seq_len 20\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Typical Settings File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` json\n",
    "{\n",
    "    \"train_data\":               \"../../data/HFR/train.txt\",\n",
    "    \"test_data\":                \"../../data/HFR/test.txt\",\n",
    "    \"val_data\":                 \"../../data/HFR/val.txt\",\n",
    "\n",
    "    \"batch_size\":               5,\n",
    "    \"epochs\":                   1000,\n",
    "\n",
    "    \"lr\":                       0.00001,\n",
    "    \"lr_decay_factor\":          0.98,\n",
    "\n",
    "    \"weight_reconstruction\":    1.0,\n",
    "    \"weight_perceptual\":        0.1,\n",
    "    \"weight_binarization\":      0.8,\n",
    "    \"weight_hinge\":             0.8,\n",
    "\n",
    "    \"crop_size\":                [224, 224],\n",
    "\n",
    "    \"device\":                   \"cuda\",\n",
    "    \"gpus\":                     [2, 3],\n",
    "    \"num_workers\":              4,\n",
    "\n",
    "    \"log_interval\":             100,\n",
    "    \"log_dir\":                  \"../../runs/flow/layered/01-initial\",\n",
    "    \"save\":                     \"checkpoint.pt\",\n",
    "    \"resume\":                   false,\n",
    "\n",
    "    \"comment\":                  \"Layered representation for optical flow. The mask is now used to inpaint only the background. Added an extra conv layer to the upsampling block in M. Jin's network. The Inpainter now also takes the mask as input, and the non-inpainted pixels are replaced with the original values. The frame skip is now 10 instead of 5.\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading the Settings File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from argparse import Namespace\n",
    "\n",
    "\n",
    "def load_config(file):\n",
    "    with open(file, 'r') as f:\n",
    "        config = json.load(f)\n",
    "        config = Namespace(**config)\n",
    "    return config\n",
    "\n",
    "def backup_config(file, log_dir):\n",
    "    # backup the config file to the log-folder\n",
    "    shutil.copy(file, os.path.join(log_dir, os.path.basename(file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Alternatives: \n",
    "\n",
    "- YAML\n",
    "- Text file\n",
    "- Bash file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Checkpoints!\n",
    "You should use them. If computer crashes, no need to train from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "model = models.resnet18(pretrained=True)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Not recommended\n",
    "torch.save(model, 'runs/full-model.pth')\n",
    "\n",
    "# Better:\n",
    "torch.save(model.state_dict(), 'runs/full-model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Even better, save additional stuff!\n",
    "torch.save({\n",
    "    'epoch': 10,\n",
    "    'model': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'val_loss': 0.456,\n",
    "    'is_best': True,\n",
    "}, 'runs/state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the checkpoint\n",
    "state = torch.load('runs/state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(state['epoch'])\n",
    "print(state['is_best'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state['model'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why Checkpoints\n",
    "\n",
    "- Computers like to crash for unknown reasons\n",
    "- Early stopping\n",
    "- Researchers appreciate if you publish the weights/checkpoints\n",
    "- Finetuning on new task\n",
    "\n",
    "Recommendation:\n",
    "- 1 checkpoint per epoch\n",
    "- If file is large: keep latest N checkpoints, delete rest.\n",
    "- Always keep track of *best* checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Repoducibility\n",
    "\n",
    "These days, researchers give a shit about reproducibility (my experience).\n",
    "This must change!\n",
    "\n",
    "- Source code should be self-contained\n",
    "- Requirements go into requirements.txt file!\n",
    "- Provide the code for ALL of your experiments\n",
    "- Publish network weights\n",
    "- Report final numbers with manual random seed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# CUDA RNG\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# If you use numpy as well ...\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# ... or random package\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Help others porting your code!\n",
    "\n",
    "- Publish error curves (training, validation, etc.) ...\n",
    "- ... or just the error after first weight update (fixed seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Useful Tools and Tricks\n",
    "\n",
    "Not really best practice but useful to know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Command line tools\n",
    "- GPU usage\n",
    "    ```\n",
    "    watch -n 0.5 nvidia-smi\n",
    "    ```\n",
    "- CPU usage\n",
    "    ```\n",
    "    htop\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./figures/nvidia-smi.png\" width=\"50%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./figures/htop.png\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Data Loading\n",
    "\n",
    "Sometimes data pre-processing is heavy. Need fast read-access to data.\n",
    "\n",
    "- Load dataset into RAM:\n",
    "    ``` cp -r path/to/my/dataset /dev/shm/ ```\n",
    "- Works only if your dataset fits into memory (duh!)\n",
    "- For proof of concept, entire dataset often not needed anyway\n",
    "\n",
    "You can increase the shared memory by editing the [``` /etc/fstab ```](https://masukkhan.wordpress.com/2015/12/09/resize-devshm-filesystem-in-linux/) file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Useful Links\n",
    "\n",
    "##### A Recipe for Training Neural Networks:\n",
    "[https://karpathy.github.io/2019/04/25/recipe/](https://karpathy.github.io/2019/04/25/recipe/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
